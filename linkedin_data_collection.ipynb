{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea49d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "from parsel import Selector\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8beb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING DRIVER TO GO TARGETED WEBSITE LINKEDIN - NEED TO INSTALL CHROME DRIVER BEFORE RUN SCRIPT\n",
    "PATH = './chromedriver'\n",
    "browser = webdriver.Chrome(PATH)\n",
    "browser.get('https://www.linkedin.com/')\n",
    "browser.maximize_window()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69bcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGIN PROCEDURE - NOTE THAT USING A CLONE ACCOUNT TO AVOID BANNING FROM LINKEDIN\n",
    "username = browser.find_element('id', 'session_key')\n",
    "username.send_keys('email_address') # Change your account to log in\n",
    "password = browser.find_element('id', 'session_password')\n",
    "password.send_keys('password') # your password to log in\n",
    "browser.find_element(By.CLASS_NAME,'sign-in-form__submit-button').click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO TO JOB SEARCH\n",
    "browser.get('https://www.linkedin.com/jobs/search/')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEARCH ALL JOB RELATED TO DATA\n",
    "job_search = browser.find_element(By.CLASS_NAME, \"jobs-search-box__text-input\")\n",
    "job_search.send_keys('data')\n",
    "job_loc_search = browser.find_element(By.XPATH, '//input[@aria-label=\"City, state, or zip code\"]')\n",
    "job_loc_search.clear()\n",
    "job_loc_search.send_keys('Ontario')\n",
    "browser.find_element(By.CLASS_NAME, \"jobs-search-box__submit-button\").click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aef2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING FOR GET JOB_ID\n",
    "def get_job_id(url):\n",
    "    a = re.search('\\d{10,11}',url).group()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DUMMY VARIABLE\n",
    "raw_job =pd.DataFrame()\n",
    "job_list = []\n",
    "job_main_info_list = []\n",
    "list_url = []\n",
    "check = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf58ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT THE DATA\n",
    "for page in range(1,51): \n",
    "    job_cards = browser.find_elements(By.XPATH, '//ul[@class=\"scaffold-layout__list-container\"]/li')\n",
    "    card_ids = [result.get_attribute('id') for result in job_cards]\n",
    "    url = browser.current_url\n",
    "    response = requests.request('GET', url)\n",
    "    content = response.content.decode('utf-8')\n",
    "    soup = bs(content, 'html.parser')\n",
    "    items = soup.find('ul', {'class': 'jobs-search__results-list'})\n",
    "    ## GET URL\n",
    "    job_links = [i[\"href\"].strip('\\n ') for i in items.find_all('a', {'class': 'base-card__full-link'})]\n",
    "    job_id_list = [get_job_id(link) for link in job_links]\n",
    "    ## GO TO EACH JOB CARD BY URL TO GET DATA FIELDS\n",
    "    for job_id in job_id_list:\n",
    "        try:\n",
    "            # JOB TITLE - JOB DES - COMPANY - LOCATION\n",
    "            job_title = browser.find_element(By.XPATH, \"//h2[@class='t-24 t-bold jobs-unified-top-card__job-title']\").text\n",
    "            job_description = browser.find_element(By.XPATH, '//div[@id=\"job-details\"]').text.replace('\\n',' ')\n",
    "            job_company = items.find('h4', {'class': 'base-search-card__subtitle'}).text.strip('\\n ')\n",
    "            job_location = items.find('span', {'class': 'job-search-card__location'}).text.strip('\\n ')\n",
    "        except:\n",
    "            job_title =''\n",
    "            job_description = ''\n",
    "            job_company = ''\n",
    "            job_location = ''\n",
    "        try:\n",
    "            # JOB POST DATE - NUMBER APPLICATION\n",
    "            sub_card_2 = browser.find_element(By.XPATH, \"//span[@class='jobs-unified-top-card__subtitle-secondary-grouping t-black--light']\").find_elements(By.TAG_NAME, 'span')\n",
    "            job_post_date = sub_card_2[0].text\n",
    "            job_no_of_app = sub_card_2[1].text\n",
    "        except:\n",
    "            job_post_date = ''\n",
    "            job_no_of_app = ''\n",
    "        try:\n",
    "            #SALARY - JOB TYPE - JOB LEVEL\n",
    "            sub_card_3 = browser.find_elements(By.XPATH, '//div[@class=\"mt5 mb2\"]/ul//li')\n",
    "            if sub_card_3[0].text != '':\n",
    "                job_info = sub_card_3[0].text.split(\" · \")\n",
    "                if (len(job_info) == 1):\n",
    "                    job_salary = ''\n",
    "                    job_work_dur = job_info[0]\n",
    "                    job_pos_title = ''\n",
    "                elif (len(job_info) == 2):\n",
    "                    job_salary = ''\n",
    "                    job_work_dur = job_info[0]\n",
    "                    job_pos_title = job_info[1]\n",
    "                else:\n",
    "                    job_salary = job_info[0]\n",
    "                    job_work_dur = job_info[1]\n",
    "                    job_pos_title = job_info[2]\n",
    "            else:\n",
    "                job_salary = ''\n",
    "                job_work_dur = ''\n",
    "                job_pos_title = ''\n",
    "\n",
    "            if sub_card_3[1].text != '':\n",
    "                job_info = sub_card_3[1].text.split(\" · \")\n",
    "                if len(job_info) == 2:\n",
    "                    company_size = job_info[0]\n",
    "                    company_sector = job_info[1]\n",
    "                elif len(job_info) == 1:\n",
    "                    company_size = job_info[0]\n",
    "                    company_sector = ''\n",
    "                else:\n",
    "                    company_size = ''\n",
    "                    company_sector = ''\n",
    "            else:\n",
    "                company_size = ''\n",
    "                company_sector = ''\n",
    "        except:\n",
    "            job_salary = ''\n",
    "            job_work_dur = ''\n",
    "            job_pos_title = ''\n",
    "            company_size = ''\n",
    "            company_sector = ''\n",
    "            time.sleep(5)\n",
    "        try:\n",
    "            job_data = [job_title,job_company,job_location,job_salary,job_work_dur,job_pos_title,company_size,company_sector,job_post_date,job_no_of_app,job_description]\n",
    "            job_list.append(job_data)\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            #CHANGE URL FOR NEXT JOB\n",
    "            get_url = browser.current_url\n",
    "            new_url = get_url.replace(get_job_id(get_url),job_id)\n",
    "            browser.get(new_url)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            continue\n",
    "            check += 1\n",
    "            if check >= len(job_id_list):\n",
    "                break\n",
    "            else:\n",
    "                continue \n",
    "    # GO TO NEXT PAGE OF JOB SEARCH\n",
    "    browser.find_element(By.XPATH, f'//button[@aria-label=\"Page {page}\"]').click()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f98135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT TO DATAFRAME\n",
    "raw_data = pd.DataFrame(job_list, columns = ['job_title',\n",
    "                                             'company_name',\n",
    "                                             'location',\n",
    "                                             'salary',\n",
    "                                             'job_type',\n",
    "                                             'job_level',\n",
    "                                             'company_size',\n",
    "                                             'industry',\n",
    "                                             'date_post',\n",
    "                                             'num_application',\n",
    "                                             'job_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdcee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT TO CSV\n",
    "raw_data.to_csv('linkedin_raw_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
